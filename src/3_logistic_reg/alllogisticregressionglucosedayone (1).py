# -*- coding: utf-8 -*-
"""AllLogisticRegressionGlucoseDayOne.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cPrcQnLOcDRDk2cRI61K7B64ldi7azTy
"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
from sklearn.utils import resample
from imblearn.over_sampling import SMOTE
import numpy as np
import random
import sklearn

from google.colab import drive
drive.mount('/content/drive')
from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()

import pandas as pd
data = pd.read_csv('/content/drive/MyDrive/GlucoseData/Regression models/cohortedData.csv')
data.fillna(0, inplace=True)

data.columns

data['major_surgery'].unique()

data['admElective'] = label_encoder.fit_transform(data['admElective'])
data['hadMeasurmentDayOne'] = label_encoder.fit_transform(data['hadMeasurmentDayOne'])


niceColumns=['isMale','english_Proficent','copd_present','diabetes','asthma_present','admElective','hadSteroid','major_surgery'] #, lab values (yes/no, if taken), 'hadSteroid','major_surgery'
#niceColumns=["uti", "biliary", "skin", 'hypertension_present','heart_failure_present','copd_present','cad_present','diabetes','isMale','ckd_stages','hadInsulinDayOne','english_Proficent']

categorical_vars = ['insurance','anchor_year_group','race_group']
dummy_vars = pd.get_dummies(data[categorical_vars])
dummy_vars = dummy_vars.drop(columns=['race_group_White'])
dummy_vars = dummy_vars.drop(columns=['anchor_year_group_2008 - 2010'])
dummy_vars = dummy_vars.drop(columns=['insurance_Other'])


data = pd.concat([data, dummy_vars], axis=1)


continuous_vars = ['age','charlson_comorbidity_index','SOFA']
#,'sofa','cardiovascular','cns','coagulation','liver','renal','respiration'
independent = data[continuous_vars + list(dummy_vars.columns)+niceColumns]

dependent = data['hadMeasurmentDayOne']

from sklearn.linear_model import LogisticRegression

X_train, X_test, y_train, y_test = train_test_split(independent, dependent, test_size=0.25, random_state=16)

log_reg = LogisticRegression()

log_reg.fit(X_train, y_train)

# Step 2: Get the logistic regression coefficients
coefficients = log_reg.coef_[0]

# Step 3: Calculate odds ratios by exponentiating the coefficients
odds_ratios = np.exp(coefficients)

from scipy.stats import norm

coefs = log_reg.coef_[0]
std_errors = np.sqrt(np.diag(np.linalg.inv(np.dot(X_train.T, X_train))))

# Define desired confidence level (e.g., 95% confidence interval)
confidence_level = 0.95

# Calculate z-score for the critical value
critical_value = norm.ppf((1 + confidence_level) / 2)

# Calculate lower and upper bounds of the confidence interval
lower_bounds =  np.exp(coefs - (critical_value * std_errors))
upper_bounds = np.exp(coefs + (critical_value * std_errors))
variable_names=independent.columns
result=pd.DataFrame({'Variable': variable_names, 'Odds Ratio': odds_ratios,'low': lower_bounds, 'up':upper_bounds})
print(result)

data['hadMeasurmentDayOne'].describe()

result.head()
result['Variable'] = result['Variable'].replace('insurance_Medicaid', 'Medicaid')
result['Variable'] = result['Variable'].replace('insurance_Medicare', 'Medicare')
result['Variable'] = result['Variable'].replace('charlson_comorbidity_index', 'CCI')
result['Variable'] = result['Variable'].replace('race_group_Asian', 'Asian')
result['Variable'] = result['Variable'].replace('race_group_Black', 'Black')
result['Variable'] = result['Variable'].replace('race_group_Hispanic', 'Hispanic')
result['Variable'] = result['Variable'].replace('major_surgery', 'surgery')
result['Variable'] = result['Variable'].replace('anchor_year_group_2017 - 2019', '2017-2019')
result['Variable'] = result['Variable'].replace('anchor_year_group_2014 - 2016', '2014-2016')
result['Variable'] = result['Variable'].replace('anchor_year_group_2011 - 2013', '2011-2013')

from google.colab import files

result.to_excel('logregSum.xlsx',index=False)
files.download('logregSum.xlsx')

import pandas as pd
import matplotlib.pyplot as plt




# Create the forest plot
plt.figure(figsize=(10, len(result) * 0.3))  # Adjust the figure size based on the number of variables
plt.errorbar(result['Odds Ratio'], result['Variable'], xerr=[result['Odds Ratio'] - result['low'], result['up'] - result['Odds Ratio']],
             fmt='o', color='blue', capsize=5)
plt.axvline(x=1.0, color='gray', linestyle='--')
plt.xlabel('Odds Ratio')
plt.ylabel('Variable')
plt.title('Forest Plot')
plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.xlim(0.3, 2.2)

plt.show()

#asthma should be with COPD
#steroid together with diabetes
#dag

predicted_probs = log_reg.predict(X_test)
# Convert predicted probabilities to binary predictions (0 or 1)
predicted_values = (predicted_probs >= 0.5).astype(int)

# Compare predicted values with actual values and calculate accuracy
accuracy = (predicted_values == y_test).mean()
print(accuracy)