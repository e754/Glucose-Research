{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nIb9_6pTXpL0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.utils import resample\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GZt3zq6eiXSy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "current_path = os.path.abspath('.')\n",
        "label_encoder = LabelEncoder()\n",
        "fi=os.path.abspath('../../data/cohorted_Data.csv')\n",
        "data = pd.read_csv(fi)\n",
        "data.fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KSq84CwNnsW-"
      },
      "outputs": [],
      "source": [
        "data['admElective'] = label_encoder.fit_transform(data['admElective'])\n",
        "data['hadMeasurmentDayOne'] = label_encoder.fit_transform(data['hadMeasurmentDayOne'])\n",
        "\n",
        "\n",
        "niceColumns=['isMale','english_Proficent','copd_present','diabetes','asthma_present','admElective','hadSteroid','major_surgery'] #, lab values (yes/no, if taken), 'hadSteroid','major_surgery'\n",
        "#niceColumns=[\"uti\", \"biliary\", \"skin\", 'hypertension_present','heart_failure_present','copd_present','cad_present','diabetes','isMale','ckd_stages','hadInsulinDayOne','english_Proficent']\n",
        "\n",
        "categorical_vars = ['insurance','anchor_year_group','race_group']\n",
        "dummy_vars = pd.get_dummies(data[categorical_vars])\n",
        "dummy_vars = dummy_vars.drop(columns=['race_group_White'])\n",
        "dummy_vars = dummy_vars.drop(columns=['anchor_year_group_2008 - 2010'])\n",
        "dummy_vars = dummy_vars.drop(columns=['insurance_Other'])\n",
        "\n",
        "\n",
        "data = pd.concat([data, dummy_vars], axis=1)\n",
        "\n",
        "\n",
        "continuous_vars = ['age','charlson_comorbidity_index','SOFA']\n",
        "#,'sofa','cardiovascular','cns','coagulation','liver','renal','respiration'\n",
        "independent = data[continuous_vars + list(dummy_vars.columns)+niceColumns]\n",
        "\n",
        "dependent = data['hadMeasurmentDayOne']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7GGWqRgqxLr",
        "outputId": "59d7b9a8-81a3-435c-fdbd-113ab28653a9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(independent, dependent, test_size=0.25, random_state=16)\n",
        "\n",
        "log_reg = LogisticRegression()\n",
        "\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Step 2: Get the logistic regression coefficients\n",
        "coefficients = log_reg.coef_[0]\n",
        "\n",
        "# Step 3: Calculate odds ratios by exponentiating the coefficients\n",
        "odds_ratios = np.exp(coefficients)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UZbD7QpUjDTS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from scipy.linalg import inv\n",
        "\n",
        "\n",
        "coef = log_reg.coef_[0]\n",
        "intercept = log_reg.intercept_[0]\n",
        "\n",
        "# Calculate the variance-covariance matrix\n",
        "# Use the Hessian formula for logistic regression: H = X.T * W * X\n",
        "# where W is a diagonal matrix of weights, calculated as w_i = p_i * (1 - p_i)\n",
        "pred_proba = log_reg.predict_proba(X_train)[:, 1]\n",
        "W = np.diag(pred_proba * (1 - pred_proba))\n",
        "X_design = np.hstack([np.ones((X_train.shape[0], 1)), X_train])  # add a column for the intercept\n",
        "Hessian = X_design.T.dot(W).dot(X_design)\n",
        "cov_matrix = inv(Hessian)\n",
        "\n",
        "# Extract the standard errors\n",
        "std_errors = np.sqrt(np.diag(cov_matrix))\n",
        "conf_intervals = [(coef - 1.96 * se, coef + 1.96 * se) for coef, se in zip(np.append(intercept, coef), std_errors)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsAO6pa_u7IZ",
        "outputId": "f5cffb68-328d-42c6-f05a-3ea81f463341"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import norm\n",
        "\n",
        "coefs = log_reg.coef_[0]\n",
        "std_errors = np.sqrt(np.diag(np.linalg.inv(np.dot(X_train.T, X_train))))\n",
        "\n",
        "# Define desired confidence level (e.g., 95% confidence interval)\n",
        "confidence_level = 0.95\n",
        "\n",
        "# Calculate z-score for the critical value\n",
        "critical_value = norm.ppf((1 + confidence_level) / 2)\n",
        "\n",
        "# Calculate lower and upper bounds of the confidence interval\n",
        "lower_bounds =  np.exp(coefs - (critical_value * std_errors))\n",
        "upper_bounds = np.exp(coefs + (critical_value * std_errors))\n",
        "variable_names=independent.columns\n",
        "result=pd.DataFrame({'Variable': variable_names, 'Odds Ratio': odds_ratios,'low': lower_bounds, 'up':upper_bounds})\n",
        "\n",
        "interceptRow={'Variable':\"Intercept\",'Odds Ratio':intercept,'low':conf_intervals[0][0],'up':conf_intervals[0][1]}\n",
        "\n",
        "result.loc[-1] = interceptRow\n",
        "result.index = result.index + 1\n",
        "result = result.sort_index()\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6J8GI0TR9ov",
        "outputId": "ff04484e-0090-4ec0-cbd2-79577e349554"
      },
      "outputs": [],
      "source": [
        "data['hadMeasurmentDayOne'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfFr65i5FXJS"
      },
      "outputs": [],
      "source": [
        "result.head()\n",
        "result['Variable'] = result['Variable'].replace('insurance_Medicaid', 'Medicaid')\n",
        "result['Variable'] = result['Variable'].replace('insurance_Medicare', 'Medicare')\n",
        "result['Variable'] = result['Variable'].replace('charlson_comorbidity_index', 'Charlson comorbidity index')\n",
        "result['Variable'] = result['Variable'].replace('race_group_Asian', 'Asian')\n",
        "result['Variable'] = result['Variable'].replace('race_group_Black', 'Black')\n",
        "result['Variable'] = result['Variable'].replace('race_group_Hispanic', 'Hispanic')\n",
        "result['Variable'] = result['Variable'].replace('major_surgery', 'Major Surgery')\n",
        "result['Variable'] = result['Variable'].replace('anchor_year_group_2017 - 2019', '2017-2019')\n",
        "result['Variable'] = result['Variable'].replace('anchor_year_group_2014 - 2016', '2014-2016')\n",
        "result['Variable'] = result['Variable'].replace('anchor_year_group_2011 - 2013', '2011-2013')\n",
        "result['Variable'] = result['Variable'].replace('english_Proficent', 'English proficient')\n",
        "result['Variable'] = result['Variable'].replace('age', 'Age')\n",
        "result['Variable'] = result['Variable'].replace('hadSteroid', 'Had steroid')\n",
        "result['Variable'] = result['Variable'].replace('admElective', 'Elective admission')\n",
        "result['Variable'] = result['Variable'].replace('asthma_present', 'Asthma present')\n",
        "result['Variable'] = result['Variable'].replace('diabetes', 'Diabetes present')\n",
        "result['Variable'] = result['Variable'].replace('copd_present', 'COPD present')\n",
        "result['Variable'] = result['Variable'].replace('isMale', 'Sex Male')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "0evPqlqj4vkm",
        "outputId": "5e1d1603-d6c4-4bf5-8dd2-5d9b1ca15742"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "result.to_excel('logregSum.xlsx',index=False)\n",
        "files.download('logregSum.xlsx')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "cTY1kxHvbGN4",
        "outputId": "71fad27e-220d-4481-9250-a02f8eb530af"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create the forest plot\n",
        "plt.figure(figsize=(10, len(result) * 0.3))  # Adjust the figure size based on the number of variables\n",
        "plt.errorbar(result['Odds Ratio'], result['Variable'], xerr=[result['Odds Ratio'] - result['low'], result['up'] - result['Odds Ratio']],\n",
        "             fmt='o', color='teal', capsize=5)\n",
        "plt.axvline(x=1.0, color='gray', linestyle='--')\n",
        "plt.xlabel('Odds Ratio')\n",
        "plt.ylabel('Variable')\n",
        "plt.title('Logistic Regression Odds Ratio Forest Plot')\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.xlim(0.5, 2.25)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "#asthma should be with COPD\n",
        "#steroid together with diabetes\n",
        "#dag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3WDj_UUS6tJ",
        "outputId": "4c098563-1202-4dec-f0df-5f25d7d0f663"
      },
      "outputs": [],
      "source": [
        "predicted_probs = log_reg.predict(X_test)\n",
        "# Convert predicted probabilities to binary predictions (0 or 1)\n",
        "predicted_values = (predicted_probs >= 0.5).astype(int)\n",
        "\n",
        "# Compare predicted values with actual values and calculate accuracy\n",
        "accuracy = (predicted_values == y_test).mean()\n",
        "print(accuracy)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
